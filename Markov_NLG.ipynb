{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import tools"
      ],
      "metadata": {
        "id": "rMQpB9KGQX7f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gingerit\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-7Sa6n3SoyL",
        "outputId": "f73faf9d-2229-4072-dc97-2830e083dd02"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gingerit\n",
            "  Downloading gingerit-0.9.0-py3-none-any.whl (3.4 kB)\n",
            "Collecting cloudscraper<2.0.0,>=1.2.66 (from gingerit)\n",
            "  Downloading cloudscraper-1.2.71-py2.py3-none-any.whl (99 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m99.7/99.7 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyparsing>=2.4.7 in /usr/local/lib/python3.10/dist-packages (from cloudscraper<2.0.0,>=1.2.66->gingerit) (3.1.0)\n",
            "Requirement already satisfied: requests>=2.9.2 in /usr/local/lib/python3.10/dist-packages (from cloudscraper<2.0.0,>=1.2.66->gingerit) (2.27.1)\n",
            "Collecting requests-toolbelt>=0.9.1 (from cloudscraper<2.0.0,>=1.2.66->gingerit)\n",
            "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.9.2->cloudscraper<2.0.0,>=1.2.66->gingerit) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.9.2->cloudscraper<2.0.0,>=1.2.66->gingerit) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.9.2->cloudscraper<2.0.0,>=1.2.66->gingerit) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.9.2->cloudscraper<2.0.0,>=1.2.66->gingerit) (3.4)\n",
            "Installing collected packages: requests-toolbelt, cloudscraper, gingerit\n",
            "Successfully installed cloudscraper-1.2.71 gingerit-0.9.0 requests-toolbelt-1.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import random\n",
        "import spacy\n",
        "from gingerit.gingerit import GingerIt\n",
        "\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "3nhKu0pq1cue",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98b5e7a4-ddf7-41fb-a594-b87cd6020117"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Reading the text files"
      ],
      "metadata": {
        "id": "P6g2Dal2Qe3W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "txt=[]\n",
        "from google.colab import files\n",
        "uploaded_files = files.upload()\n",
        "\n",
        "for file in uploaded_files.keys():\n",
        "  with open(file) as f:\n",
        "    for line in f:\n",
        "      line = line.strip()\n",
        "      if line=='----------': break\n",
        "      if line!='':txt.append(line)\n",
        "\n",
        "print(\"number of lines = \", len(txt))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "FLe59CClRMuN",
        "outputId": "77687e9d-8dc5-4035-d094-af5a1a015da1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-5855e3a5-9095-4b8b-aee2-9c8a007e27c9\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-5855e3a5-9095-4b8b-aee2-9c8a007e27c9\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Statistics.txt to Statistics.txt\n",
            "number of lines =  549\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cleaning the text"
      ],
      "metadata": {
        "id": "pFkH4IX9XJOd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_txt(txt):\n",
        "    cleaned_txt = []\n",
        "    for line in txt:\n",
        "        line = line.lower()\n",
        "        line = re.sub(r\"[,.\\\"\\'!@#$%^&*(){}?/;`~:<>+=-\\\\]\", \"\", line)\n",
        "        tokens = word_tokenize(line)\n",
        "        words = [word for word in tokens if word.isalpha()]\n",
        "        cleaned_txt+=words\n",
        "    return cleaned_txt\n",
        "\n",
        "cleaned_txt = clean_txt(txt)\n",
        "print(\"number of words = \", len(cleaned_txt))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYcf_FmxXM5P",
        "outputId": "ffd8d6e4-3ba1-40b4-b4ef-4f0965b15aba"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of words =  2293\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the model"
      ],
      "metadata": {
        "id": "QQOa__MD9Zgr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_markov_model(cleaned_stories, n_gram=2):\n",
        "    markov_model = {}\n",
        "    for i in range(len(cleaned_stories)-n_gram-1):\n",
        "        curr_state, next_state = \"\", \"\"\n",
        "        for j in range(n_gram):\n",
        "            curr_state += cleaned_stories[i+j] + \" \"\n",
        "            next_state += cleaned_stories[i+j+n_gram] + \" \"\n",
        "        curr_state = curr_state[:-1]\n",
        "        next_state = next_state[:-1]\n",
        "        if curr_state not in markov_model:\n",
        "            markov_model[curr_state] = {}\n",
        "            markov_model[curr_state][next_state] = 1\n",
        "        else:\n",
        "            if next_state in markov_model[curr_state]:\n",
        "                markov_model[curr_state][next_state] += 1\n",
        "            else:\n",
        "                markov_model[curr_state][next_state] = 1\n",
        "\n",
        "    # calculating transition probabilities\n",
        "    for curr_state, transition in markov_model.items():\n",
        "        total = sum(transition.values())\n",
        "        for state, count in transition.items():\n",
        "            markov_model[curr_state][state] = count/total\n",
        "\n",
        "    return markov_model"
      ],
      "metadata": {
        "id": "w3gdhCaAV_Wr"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "markov_model = make_markov_model(cleaned_txt)\n",
        "print(\"number of states = \", len(markov_model.keys()))\n",
        "markov_model.keys()"
      ],
      "metadata": {
        "id": "teHrdo5ajbEQ",
        "outputId": "8e427ceb-bb65-4974-b789-f7dd357ed1d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of states =  1600\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['a level', 'level maths', 'maths statistics', 'statistics revision', 'revision notes', 'notes planning', 'planning and', 'and data', 'data collection', 'collection problem', 'problem specification', 'specification and', 'and analysis', 'analysis what', 'what is', 'is the', 'the purpose', 'purpose of', 'of the', 'the investigation', 'investigation what', 'what data', 'data is', 'is needed', 'needed how', 'how will', 'will the', 'the data', 'data be', 'be used', 'used data', 'collection how', 'be collected', 'collected how', 'will bias', 'bias be', 'be avoided', 'avoided what', 'what sample', 'sample size', 'size is', 'needed processing', 'processing and', 'and representing', 'representing how', 'be cleaned', 'cleaned which', 'which measures', 'measures will', 'will be', 'be calculated', 'calculated how', 'be represented', 'represented interpreting', 'interpreting and', 'and discussing', 'discussing data', 'collection types', 'types of', 'of data', 'data categorialqualitative', 'categorialqualitative data', 'data descriptive', 'descriptive numerical', 'numerical quantitative', 'quantitative data', 'data sampling', 'sampling techniques', 'techniques simple', 'simple random', 'random sampling', 'sampling each', 'each member', 'member of', 'the population', 'population has', 'has an', 'an equal', 'equal chance', 'chance of', 'of being', 'being selected', 'selected for', 'for the', 'the sample', 'sample systematic', 'systematic choosing', 'choosing from', 'from a', 'a sampling', 'sampling frame', 'frame if', 'if the', 'is numbered', 'numbered select', 'select the', 'the starting', 'starting point', 'point and', 'and then', 'then select', 'select every', 'every nth', 'nth item', 'item in', 'in the', 'the list', 'list stratified', 'stratified a', 'a stratified', 'stratified sample', 'sample is', 'is one', 'one that', 'that ensures', 'ensures that', 'that subgroups', 'subgroups strata', 'strata of', 'of a', 'a given', 'given population', 'population are', 'are each', 'each adequately', 'adequately represented', 'represented within', 'within the', 'the whole', 'whole sample', 'sample population', 'population of', 'a research', 'research study', 'study sample', 'size from', 'from each', 'each subgroup', 'subgroup ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ', 'ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘  ğ‘œğ‘œğ‘œğ‘œ', 'ğ‘œğ‘œğ‘œğ‘œ ğ‘¤ğ‘¤â„ğ‘œğ‘œğ‘œğ‘œğ‘œğ‘œ', 'ğ‘¤ğ‘¤â„ğ‘œğ‘œğ‘œğ‘œğ‘œğ‘œ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ', 'ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘  ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘', 'ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ ğ‘œğ‘œğ‘œğ‘œ', 'ğ‘œğ‘œğ‘œğ‘œ ğ‘¡ğ‘¡â„ğ‘’ğ‘’', 'ğ‘¡ğ‘¡â„ğ‘’ğ‘’ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ', 'ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘  ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ğ‘ ', 'ğ‘¤ğ‘¤â„ğ‘œğ‘œğ‘œğ‘œğ‘œğ‘œ ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘', 'ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ quota', 'quota sampling', 'sampling sample', 'sample selected', 'selected based', 'based on', 'on specific', 'specific criteria', 'criteria eg', 'eg age', 'age group', 'group convenience', 'convenience opportunity', 'opportunity sampling', 'sampling eg', 'eg the', 'the first', 'first people', 'people who', 'who enter', 'enter a', 'a leisure', 'leisure centre', 'centre or', 'or teachers', 'teachers in', 'in single', 'single primary', 'primary school', 'school surveyed', 'surveyed to', 'to find', 'find information', 'information about', 'about working', 'working in', 'in primary', 'primary education', 'education across', 'across the', 'the uk', 'uk self', 'self selecting', 'selecting sample', 'sample people', 'people volunteer', 'volunteer to', 'to take', 'take part', 'part in', 'in a', 'a survey', 'survey either', 'either remotely', 'remotely internet', 'internet or', 'or in', 'in person', 'person processing', 'and representation', 'representation categorialqualitative', 'data pie', 'pie charts', 'charts bar', 'bar charts', 'charts with', 'with spaces', 'spaces between', 'between the', 'the bars', 'bars compoundmultiple', 'compoundmultiple bar', 'charts dot', 'dot charts', 'charts pictograms', 'pictograms wwwmathsboxorguk', 'wwwmathsboxorguk modal', 'modal class', 'class used', 'used as', 'as a', 'a summary', 'summary measure', 'measure numerical', 'data represented', 'represented using', 'using frequency', 'frequency diagrams', 'diagrams histograms', 'histograms cumulative', 'cumulative frequency', 'diagrams box', 'box and', 'and whisker', 'whisker plots', 'plots measures', 'measures of', 'of central', 'central tendency', 'tendency mode', 'mode can', 'can have', 'have more', 'more than', 'than one', 'one mode', 'mode median', 'median middle', 'middle value', 'value of', 'of ordered', 'ordered data', 'data ğ‘¥ğ‘¥', 'ğ‘¥ğ‘¥ ğ‘“ğ‘“ğ‘“ğ‘“', 'ğ‘“ğ‘“ğ‘“ğ‘“ mean', 'mean ğ‘›ğ‘›', 'ğ‘›ğ‘› or', 'or ğ‘“ğ‘“', 'ğ‘“ğ‘“ if', 'the mean', 'mean is', 'is calculated', 'calculated from', 'from grouped', 'grouped data', 'data it', 'it will', 'be an', 'an estimated', 'estimated mean', 'mean measures', 'of spread', 'spread range', 'range largest', 'largest smallest', 'smallest value', 'value inter', 'inter quartile', 'quartile range', 'range upper', 'upper quartile', 'quartile lower', 'lower quartile', 'quartile not', 'not influenced', 'influenced by', 'by extreme', 'extreme values', 'values standard', 'standard deviation', 'deviation includes', 'includes all', 'all the', 'sample finding', 'finding the', 'the quartiles', 'quartiles sample', 'size n', 'n n', 'n is', 'is odd', 'odd data', 'data median', 'median upper', 'quartile middle', 'data greater', 'greater than', 'than the', 'the median', 'median lower', 'data less', 'less than', 'median n', 'is even', 'even data', 'data lq', 'lq median', 'the lower', 'lower half', 'half of', 'data uq', 'uq upper', 'the upper', 'upper half', 'data standard', 'deviation sample', 'sample ğ‘†ğ‘†', 'ğ‘†ğ‘† ğ‘¥ğ‘¥ğ‘¥ğ‘¥', 'ğ‘¥ğ‘¥ğ‘¥ğ‘¥ s', 's where', 'where ğ‘†ğ‘†ğ‘¥ğ‘¥ğ‘¥ğ‘¥', 'ğ‘†ğ‘†ğ‘¥ğ‘¥ğ‘¥ğ‘¥ or', 'or ğ‘†ğ‘†ğ‘¥ğ‘¥ğ‘¥ğ‘¥', 'ğ‘†ğ‘†ğ‘¥ğ‘¥ğ‘¥ğ‘¥ ğ‘¥ğ‘¥', 'ğ‘¥ğ‘¥ or', 'ğ‘†ğ‘†ğ‘¥ğ‘¥ğ‘¥ğ‘¥ ğ‘“ğ‘“ğ‘¥ğ‘¥', 'ğ‘“ğ‘“ğ‘¥ğ‘¥ ğ‘†ğ‘†', 'ğ‘¥ğ‘¥ğ‘¥ğ‘¥ standard', 'deviation population', 'population standard', 'deviation ğ‘†ğ‘†', 'ğ‘†ğ‘† ğœğœ', 'ğœğœ ğ‘›ğ‘›ğ‘¥ğ‘¥ğ‘¥ğ‘¥', 'ğ‘›ğ‘›ğ‘¥ğ‘¥ğ‘¥ğ‘¥ ğ‘†ğ‘†', 'ğ‘†ğ‘† variance', 'variance ğœğœ', 'ğ‘›ğ‘›ğ‘¥ğ‘¥ğ‘¥ğ‘¥ wwwmathsboxorguk', 'wwwmathsboxorguk check', 'check with', 'with your', 'your syllabusexam', 'syllabusexam board', 'board to', 'to see', 'see if', 'if you', 'you are', 'are expected', 'expected to', 'to divide', 'divide by', 'by n', 'n or', 'or when', 'when calculating', 'calculating the', 'the standard', 'deviation bivariate', 'bivariate data', 'data investigating', 'investigating the', 'the association', 'association correlation', 'correlation between', 'between variables', 'variables the', 'the explanatorycontrolindependent', 'explanatorycontrolindependent variable', 'variable is', 'is usually', 'usually plotted', 'plotted on', 'on the', 'the horizontal', 'horizontal axis', 'axis a', 'a numerical', 'numerical measure', 'measure of', 'of correlation', 'correlation can', 'can be', 'calculated spearman', 'spearman s', 's rank', 'rank product', 'product moment', 'moment correlation', 'correlation coefficient', 'coefficient r', 'r perfect', 'perfect negative', 'negative correlation', 'correlation no', 'no correlation', 'correlation perfect', 'perfect positive', 'positive correlation', 'correlation take', 'take care', 'care when', 'when interpreting', 'interpreting the', 'the correlation', 'coefficient look', 'look at', 'at the', 'the scatter', 'scatter graph', 'graph distinct', 'distinct groups', 'groups misleading', 'misleading r', 'r value', 'value r', 'r close', 'close to', 'to zero', 'zero but', 'but there', 'there is', 'is a', 'a relationship', 'relationship quadratic', 'quadratic not', 'not linear', 'linear outlier', 'outlier distorting', 'distorting r', 'value suggesting', 'suggesting positive', 'correlation if', 'if removed', 'removed no', 'correlation cleaning', 'cleaning the', 'data removing', 'removing outliers', 'outliers or', 'or anomalies', 'anomalies remove', 'remove values', 'values which', 'which are', 'are inter', 'range above', 'above or', 'or below', 'below the', 'the ul', 'ul quartile', 'quartile remove', 'are standard', 'deviation above', 'mean probability', 'probability outcome', 'outcome an', 'an event', 'event that', 'that can', 'can happen', 'happen in', 'in an', 'an experiment', 'experiment sample', 'sample space', 'space list', 'list of', 'of all', 'the possible', 'possible outcomes', 'outcomes for', 'for an', 'experiment notation', 'notation a', 'a b', 'b a', 'a or', 'or b', 'b or', 'or both', 'both happen', 'happen a', 'a does', 'does not', 'not happen', 'b ğ´ğ´', 'ğ´ğ´ ğµğµ', 'ğµğµ a', 'a and', 'and b', 'b both', 'happen ğ´ğ´', 'ğµğµ wwwmathsboxorguk', 'wwwmathsboxorguk for', 'for independent', 'independent events', 'events pğ´ğ´', 'pğ´ğ´ ğµğµ', 'ğµğµ pğ´ğ´', 'ğµğµ pa', 'pa pb', 'pb pğ´ğ´', 'pa mutually', 'mutually exclusive', 'exclusive events', 'events two', 'two or', 'or more', 'more events', 'events which', 'which can', 'can not', 'happen at', 'the same', 'same time', 'time pğ´ğ´', 'pğ´ğ´ b', 'a pğ´ğ´', 'pb male', 'male junior', 'junior senior', 'senior total', 'total female', 'female total', 'total on', 'on his', 'his way', 'way to', 'to work', 'work josh', 'josh goes', 'goes through', 'through sets', 'sets of', 'of traffic', 'traffic lights', 'lights the', 'the probability', 'probability that', 'that he', 'he has', 'has to', 'to stop', 'stop at', 'the set', 'set is', 'is and', 'and the', 'probability for', 'is assume', 'assume independence', 'independence find', 'find the', 'probability of', 'of find', 'at only', 'only one', 'one of', 'the traffic', 'lights a', 'a picking', 'picking a', 'a female', 'female stop', 'stop and', 'and not', 'not stop', 'stop or', 'or not', 'and stop', 'stop b', 'b pickling', 'pickling a', 'a junior', 'junior male', 'male c', 'c not', 'not picking', 'male d', 'd picking', 'junior and', 'and a', 'a senior', 'senior when', 'when members', 'members are', 'are selected', 'selected at', 'at random', 'random conditional', 'conditional probability', 'probability when', 'when the', 'the outcome', 'outcome of', 'first event', 'event effects', 'effects the', 'a second', 'second event', 'event the', 'the second', 'event happening', 'happening is', 'is conditional', 'conditional on', 'happening means', 'means that', 'that the', 'of b', 'b given', 'given that', 'that a', 'a has', 'has occurred', 'occurred if', 'the probabilities', 'probabilities needed', 'needed are', 'are not', 'not stated', 'stated clearly', 'clearly a', 'a tree', 'tree diagram', 'diagram or', 'or venn', 'venn diagram', 'diagram may', 'may help', 'help ğ‘ƒğ‘ƒğ´ğ´', 'ğ‘ƒğ‘ƒğ´ğ´ so', 'so ğ‘ƒğ‘ƒğ´ğ´', 'ğ‘ƒğ‘ƒğ´ğ´ ğµğµ', 'ğµğµ ğ‘ƒğ‘ƒğ´ğ´pba', 'ğ‘ƒğ‘ƒğ´ğ´pba dark', 'dark wrapped', 'wrapped in', 'a box', 'box of', 'of dark', 'dark and', 'and milk', 'milk chocolates', 'chocolates there', 'there are', 'are chocolates', 'chocolates of', 'the chocolates', 'chocolates are', 'are dark', 'and of', 'of these', 'these dark', 'dark chocolates', 'are wrapped', 'wrapped there', 'wrapped chocolates', 'chocolates in', 'the box', 'box given', 'a chocolate', 'chocolate chosen', 'chosen is', 'a milk', 'milk chocolate', 'chocolate what', 'that it', 'it is', 'is not', 'not wrapped', 'wrapped pnot', 'pnot wrappedmilk', 'wrappedmilk milk', 'milk ğ‘ƒğ‘ƒğ‘ğ‘ğ‘ğ‘ğ‘ğ‘', 'ğ‘ƒğ‘ƒğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤', 'ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ğ‘¤ ğ‘€ğ‘€ğ‘€ğ‘€ğ‘€ğ‘€ğ‘€ğ‘€', 'ğ‘€ğ‘€ğ‘€ğ‘€ğ‘€ğ‘€ğ‘€ğ‘€ ğ‘ƒğ‘ƒğ‘€ğ‘€ğ‘€ğ‘€ğ‘€ğ‘€ğ‘€ğ‘€', 'ğ‘ƒğ‘ƒğ‘€ğ‘€ğ‘€ğ‘€ğ‘€ğ‘€ğ‘€ğ‘€ probability', 'probability distributions', 'distributions a', 'a probability', 'probability distribution', 'distribution shows', 'shows the', 'probabilities of', 'outcomes x', 'x px', 'px x', 'x calculate', 'calculate the', 'the value', 'of y', 'y ğ‘ƒğ‘ƒğ‘‹ğ‘‹', 'ğ‘ƒğ‘ƒğ‘‹ğ‘‹ ğ‘¥ğ‘¥', 'ğ‘¥ğ‘¥ y', 'y wwwmathsboxorguk', 'wwwmathsboxorguk ğ‘ƒğ‘ƒğ‘‹ğ‘‹', 'ğ‘¥ğ‘¥ calculate', 'calculate ex', 'ex binomial', 'binomial distribution', 'distribution bnp', 'bnp possible', 'outcomes probability', 'of success', 'success p', 'p probability', 'of failure', 'failure p', 'p fixed', 'fixed number', 'number of', 'of trials', 'trials n', 'n the', 'the trials', 'trials are', 'are independent', 'independent ex', 'ex np', 'np pgetting', 'pgetting r', 'r successes', 'successes out', 'out of', 'of n', 'n trials', 'trials ncr', 'ncr ğ’‘ğ’‘ğ’“ğ’“', 'ğ’‘ğ’‘ğ’“ğ’“ research', 'research has', 'has shown', 'shown that', 'that approximately', 'approximately of', 'are left', 'left handed', 'handed a', 'a group', 'group of', 'of students', 'students are', 'random what', 'that less', 'than of', 'of them', 'them are', 'handed x', 'x number', 'of left', 'handed students', 'students p', 'p p', 'p n', 'n less', 'than px', 'px this', 'this can', 'be found', 'found using', 'using tables', 'tables using', 'using cumulative', 'cumulative tables', 'tables check', 'check if', 'you can', 'can use', 'use your', 'your calculator', 'calculator for', 'for this', 'this remember', 'remember the', 'the tables', 'tables give', 'give you', 'you less', 'than or', 'or equal', 'equal to', 'to the', 'the lookup', 'lookup value', 'value list', 'list the', 'outcomes and', 'and identify', 'identify the', 'the ones', 'ones you', 'you need', 'need to', 'to include', 'include px', 'px look', 'look up', 'up x', 'x the', 'the normal', 'normal distribution', 'distribution defined', 'defined as', 'as xnğœ‡ğœ‡', 'xnğœ‡ğœ‡ ğœğœ', 'ğœğœ where', 'where ğœ‡ğœ‡', 'ğœ‡ğœ‡ is', 'mean of', 'population and', 'and ğœğœ', 'ğœğœ is', 'the variance', 'variance symmetrical', 'symmetrical distribution', 'distribution about', 'about the', 'mean such', 'such at', 'at of', 'is within', 'within standard', 'deviation of', 'standard deviations', 'deviations of', 'mean points', 'points of', 'of inflection', 'inflection of', 'normal curve', 'curve lie', 'lie one', 'one standard', 'deviation either', 'either side', 'side of', 'mean point', 'point of', 'inflection point', 'inflection ğœ‡ğœ‡', 'ğœ‡ğœ‡ ğœğœ', 'ğœğœ ğœ‡ğœ‡', 'ğœ‡ğœ‡ ğœ‡ğœ‡', 'ğœğœ x', 'x nğœ‡ğœ‡', 'nğœ‡ğœ‡ ğœğœ', 'ğœğœ can', 'be transformed', 'transformed to', 'standard normal', 'distribution z', 'z using', 'using ğœ‡ğœ‡', 'ğœ‡ğœ‡ ğ‘§ğ‘§', 'ğ‘§ğ‘§ ğœğœ', 'ğœğœ wwwmathsboxorguk', 'wwwmathsboxorguk calculating', 'calculating probabilities', 'probabilities probabilities', 'probabilities can', 'calculated by', 'by either', 'either using', 'using the', 'the function', 'function on', 'on a', 'a calculator', 'calculator or', 'or by', 'by transforming', 'transforming the', 'the distribution', 'distribution to', 'distribution a', 'a sketch', 'sketch graph', 'graph shading', 'shading the', 'the required', 'required region', 'region is', 'a good', 'good idea', 'idea iqs', 'iqs are', 'are normally', 'normally distributed', 'distributed with', 'with mean', 'mean and', 'and standard', 'deviation what', 'what percent', 'percent of', 'population have', 'have an', 'an iq', 'iq of', 'of less', 'than x', 'px p', 'p z', 'z pz', 'pz x', 'x of', 'iq less', 'than calculating', 'mean standard', 'deviation or', 'or missing', 'missing value', 'value using', 'using inverse', 'inverse normal', 'normal if', 'probability is', 'is given', 'given then', 'then you', 'work backwards', 'backwards to', 'the missing', 'missing values', 'values the', 'the time', 'time x', 'x minutes', 'minutes to', 'to install', 'install an', 'an alarm', 'alarm system', 'system may', 'may also', 'also be', 'be assumed', 'assumed to', 'to be', 'be a', 'a normal', 'normal random', 'random variable', 'variable such', 'such that', 'that and', 'and determine', 'determine to', 'the nearest', 'nearest minute', 'minute the', 'the values', 'values for', 'of x', 'x ğœğœ', 'ğœğœ ğœğœ', 'ğœğœ use', 'use the', 'tables or', 'or the', 'the calculator', 'calculator function', 'function to', 'the z', 'z values', 'values corresponding', 'corresponding to', 'probabilities given', 'given pz', 'pz pz', 'pz ğœ‡ğœ‡', 'ğœ‡ğœ‡ solving', 'solving simultaneously', 'simultaneously gives', 'gives ğœ‡ğœ‡', 'ğœ‡ğœ‡ ğ‘šğ‘šğ‘šğ‘šğ‘šğ‘šğ‘šğ‘šğ‘šğ‘šğ‘šğ‘šğ‘šğ‘š', 'ğ‘šğ‘šğ‘šğ‘šğ‘šğ‘šğ‘šğ‘šğ‘šğ‘šğ‘šğ‘šğ‘šğ‘š ğœğœ', 'ğœğœ ğ‘šğ‘šğ‘šğ‘šğ‘šğ‘šğ‘šğ‘šğ‘šğ‘šğ‘šğ‘šğ‘šğ‘š', 'ğ‘šğ‘šğ‘šğ‘šğ‘šğ‘šğ‘šğ‘šğ‘šğ‘šğ‘šğ‘šğ‘šğ‘š using', 'to approximate', 'approximate a', 'a binomial', 'distribution for', 'for a', 'a valid', 'valid result', 'result the', 'the following', 'following conditions', 'conditions are', 'are suggested', 'suggested x', 'x bnp', 'bnp np', 'np and', 'and ie', 'ie p', 'p is', 'is close', 'to or', 'or n', 'is large', 'large if', 'the conditions', 'are true', 'true then', 'then xbnp', 'xbnp can', 'be approximated', 'approximated using', 'using x', 'x nnp', 'nnp nb', 'nb as', 'as the', 'the binomial', 'distribution is', 'is discrete', 'discrete and', 'is continuous', 'continuous some', 'some exam', 'exam boards', 'boards specify', 'specify that', 'a continuity', 'continuity correction', 'correction is', 'is used', 'used if', 'are calculating', 'calculating px', 'px you', 'you use', 'use px', 'px in', 'in your', 'your normal', 'distribution calculation', 'calculation a', 'a dice', 'dice is', 'is rolled', 'rolled times', 'times the', 'the random', 'variable x', 'x is', 'the number', 'of times', 'times three', 'three is', 'is scored', 'scored use', 'to calculate', 'calculate px', 'x can', 'approximated by', 'by x', 'x without', 'without continuity', 'correction px', 'px sf', 'sf with', 'with continuity', 'sf wwwmathsboxorguk', 'wwwmathsboxorguk sampling', 'sampling if', 'are working', 'working with', 'with the', 'a sample', 'sample of', 'of several', 'several observations', 'observations from', 'a population', 'population eg', 'eg calculating', 'is less', 'than a', 'a specified', 'specified value', 'value then', 'then the', 'following distribution', 'distribution must', 'must be', 'used where', 'where n', 'size ğœ‡ğœ‡', 'population mean', 'population variance', 'variance ğ‘›ğ‘›', 'ğ‘›ğ‘› alex', 'alex spends', 'spends x', 'minutes each', 'each day', 'day looking', 'looking at', 'at social', 'social media', 'media websites', 'websites x', 'a random', 'variable which', 'be modelled', 'modelled by', 'by a', 'distribution with', 'mean minutes', 'minutes and', 'deviation minutes', 'minutes calculate', 'that on', 'on randomly', 'randomly selected', 'selected days', 'days the', 'mean time', 'time alex', 'spends on', 'on social', 'media is', 'is greater', 'than minutes', 'minutes n', 'n hypothesis', 'hypothesis testing', 'testing binomial', 'binomial set', 'set up', 'up the', 'the hypothesis', 'hypothesis sf', 'sf p', 'p a', 'a one', 'one sided', 'sided test', 'test p', 'a two', 'two sided', 'test ho', 'ho p', 'a p', 'test state', 'state the', 'the significance', 'significance level', 'level as', 'a percentage', 'percentage the', 'lower the', 'value the', 'the more', 'more stringent', 'stringent the', 'the test', 'the distributionmodel', 'distributionmodel used', 'used in', 'test binomial', 'binomial np', 'np calculate', 'the observed', 'observed results', 'results occurring', 'occurring using', 'the assumed', 'assumed model', 'model compare', 'compare the', 'the calculated', 'calculated probability', 'probability to', 'level accept', 'accept or', 'or reject', 'reject ho', 'ho write', 'write a', 'a conclusion', 'conclusion in', 'in context', 'context reject', 'ho there', 'is sufficient', 'sufficient evidence', 'evidence to', 'to suggest', 'suggest that', 'that accept', 'accept ho', 'is insufficient', 'insufficient evidence', 'that we', 'we can', 'not reject', 'reject the', 'the null', 'null hypothesis', 'hypothesis that', 'that p', 'a the', 'that patients', 'patients have', 'have to', 'to wait', 'wait more', 'minutes at', 'at a', 'a gp', 'gp surgery', 'surgery is', 'the doctors', 'doctors claims', 'claims that', 'that there', 'a decrease', 'decrease in', 'of patients', 'patients having', 'having to', 'minutes she', 'she records', 'records the', 'the waiting', 'waiting times', 'times for', 'the next', 'next patients', 'patients and', 'and wait', 'minutes is', 'is there', 'there evidence', 'evidence at', 'the level', 'level to', 'to support', 'support the', 'doctors claim', 'claim ho', 'p significance', 'level x', 'patients waiting', 'waiting more', 'minutes x', 'x binomial', 'binomial using', 'tables px', 'px there', 'times have', 'have reduced', 'reduced therefore', 'therefore accept', 'ho and', 'and conclude', 'conclude that', 'p wwwmathsboxorguk', 'wwwmathsboxorguk critical', 'critical values', 'values and', 'and regions', 'regions for', 'the above', 'above example', 'example binomial', 'binomial significance', 'level px', 'px px', 'px critical', 'and critical', 'critical region', 'region x', 'x a', 'a sweet', 'sweet manufacturer', 'manufacturer packs', 'packs sweets', 'sweets with', 'with fruit', 'fruit and', 'the rest', 'rest mint', 'mint flavoured', 'flavoured they', 'they want', 'want to', 'to test', 'test if', 'if there', 'there has', 'has been', 'been a', 'a change', 'change in', 'the ratio', 'ratio of', 'of fruit', 'fruit to', 'to mint', 'mint flavours', 'flavours at', 'to do', 'do this', 'this they', 'they take', 'take a', 'of sweets', 'sweets what', 'what are', 'are the', 'the critical', 'critical regions', 'regions x', 'fruit sweets', 'sweets binomial', 'binomial ho', 'level tailed', 'tailed at', 'at each', 'each tail', 'tail lower', 'lower tail', 'tail px', 'px upper', 'upper tail', 'x critical', 'critical value', 'value critical', 'regions critical', 'x or', 'or x', 'x normal', 'distribution testing', 'testing for', 'for changes', 'changes in', 'mean set', 'hypothesis ğœ‡ğœ‡', 'ğœ‡ğœ‡ one', 'test mean', 'mean has', 'has decreased', 'decreased ğœ‡ğœ‡', 'ğœ‡ğœ‡ two', 'test ğœ‡ğœ‡', 'has increased', 'increased ho', 'ho ğğ', 'ğğ ğğ', 'ğğ one', 'decreased critical', 'region Î±', 'Î± ğğ', 'ğğ two', 'has changed', 'changed critical', 'region ğ›¼ğ›¼', 'ğ›¼ğ›¼ critical', 'ğ›¼ğ›¼ ğğ', 'increased critical', 'Î± investigate', 'investigate the', 'value you', 'with by', 'either method', 'method see', 'if your', 'your observed', 'observed value', 'value lies', 'lies in', 'region reject', 'reject if', 'if it', 'it does', 'does or', 'or method', 'method calculate', 'probability p', 'p value', 'of getting', 'getting the', 'value or', 'or greater', 'greater if', 'if testing', 'for increase', 'increase if', 'if is', 'is true', 'true and', 'and reject', 'level write', 'conclusion do', 'do not', 'not just', 'just state', 'state acceptreject', 'acceptreject accept', 'ho wwwmathsboxorguk', 'wwwmathsboxorguk there', 'of therefore', 'therefore we', 'that ğœ‡ğœ‡', 'ğœ‡ğœ‡ reject', 'changed and', 'and based', 'the results', 'results conclude', 'mean increaseddecreaseddoes', 'increaseddecreaseddoes not', 'not equal', 'equal the', 'test results', 'results of', 'a large', 'large group', 'are thought', 'thought to', 'to follow', 'follow a', 'points and', 'and variance', 'variance points', 'points a', 'random sample', 'students is', 'is found', 'found to', 'to have', 'have a', 'a mean', 'of points', 'points test', 'test at', 'to investigate', 'the claim', 'claim that', 'ho ğœ‡ğœ‡', 'ğœ‡ğœ‡ method', 'method critical', 'region method', 'method from', 'from calculator', 'calculator using', 'px z', 'z for', 'for significance', 'significance rearrange', 'rearrange to', 'to give', 'give x', 'x as', 'value is', 'is in', 'region indicating', 'indicating that', 'p pz', 'pz significance', 'as there', 'increased indicating', 'indicating an', 'an improved', 'improved performance', 'performance in', 'test correlation', 'coefficient testing', 'testing to', 'investigate whether', 'whether the', 'the linear', 'linear relationship', 'relationship represented', 'represented by', 'by r', 'r calculated', 'from the', 'is strong', 'strong enough', 'enough to', 'to use', 'the model', 'model the', 'the relationship', 'relationship in', 'population r', 'r correlation', 'coefficient calculated', 'calculated using', 'using sample', 'n ğœŒğœŒ', 'ğœŒğœŒ unknown', 'unknown population', 'population correlation', 'coefficient the', 'test checks', 'checks whether', 'whether ğœŒğœŒ', 'ğœŒğœŒ is', 'or significantly', 'significantly different', 'different from', 'from ho', 'ho ğœŒğœŒ', 'ğœŒğœŒ there', 'is no', 'the variables', 'variables ğœŒğœŒ', 'ğœŒğœŒ ğœŒğœŒ', 'ğœŒğœŒ the', 'the two', 'two variables', 'variables are', 'are correlated', 'correlated tailed', 'tailed test', 'test the', 'are positively', 'positively correlated', 'correlated one', 'one tailed', 'are negatively', 'negatively correlated', 'the length', 'length of', 'of service', 'service and', 'and current', 'current salary', 'salary is', 'is recorded', 'recorded for', 'for employees', 'employees in', 'large company', 'company the', 'r of', 'the employees', 'employees is', 'is test', 'between an', 'an employees', 'employees length', 'salary at', 'level ho', 'ğœŒğœŒ tailed', 'test n', 'n to', 'be significant', 'significant at', 'level the', 'of r', 'r being', 'being in', 'regions must', 'be critical', 'value from', 'from tables', 'tables leading', 'leading to', 'to a', 'a critical', 'region r', 'r and', 'and r', 'r r', 'r is', 'not in', 'region so', 'so there', 'to show', 'show that', 'that correlation', 'correlation is', 'is significantly'])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate Text"
      ],
      "metadata": {
        "id": "LgY6zOUmjkXC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_story(markov_model, limit=100, start='my god'):\n",
        "    n = 0\n",
        "    curr_state = start\n",
        "    next_state = None\n",
        "    story = \"\"\n",
        "    story += curr_state + \" \"\n",
        "    while n < limit:\n",
        "        next_state = random.choices(list(markov_model[curr_state].keys()),\n",
        "                                    list(markov_model[curr_state].values()))\n",
        "\n",
        "        curr_state = next_state[0]\n",
        "        story += curr_state + \" \"\n",
        "        n += 1\n",
        "    # story = add_punctuation(story)\n",
        "    return story"
      ],
      "metadata": {
        "id": "It_c1F0UjnKQ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def grammaticize_text(text):\n",
        "    ginger_parser = GingerIt()\n",
        "    result = ginger_parser.parse(text)\n",
        "    return result['result']"
      ],
      "metadata": {
        "id": "DVka8MPctq_A"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def grammaticize_text1(text):\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "    doc = nlp(text)\n",
        "    sentences = [sent.text.strip() for sent in doc.sents]\n",
        "    # sentences=grammaticize_text(sentences)\n",
        "    return \".\".join(sentences)\n"
      ],
      "metadata": {
        "id": "DWZNJCL1tvkb"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "story=generate_story(markov_model, start=\"upper quartile\", limit=30)\n",
        "result=grammaticize_text1(story)\n",
        "sent=grammaticize_text(result)\n",
        "# gramm_story=sent.replace(\".\\n\", \".\")\n",
        "print(\"Generated Story: \", sent)"
      ],
      "metadata": {
        "id": "vx-AM3c9mQke",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd020e66-9a5f-457d-ee7c-6604721f5de9"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Story:  upper quartile lower quartile middle value of data less than x PX x calculate the value the more stringent the test state the distribution model used in the test checks whether ğœŒğœŒ is close to or n is large if the conditions are true then xbnp can be approximated by x without continuity correction pxPXfSFith continuity correction pxPXfSFwwmathsboxorguk sampling\n"
          ]
        }
      ]
    }
  ]
}